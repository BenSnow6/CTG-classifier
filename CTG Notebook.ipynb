{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsCMWUjcBJvA"
   },
   "source": [
    "# An analysis of different neural network classification algorithms for identifying foetal wellbeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhqT6yux9zRp"
   },
   "source": [
    "- Ibeawuchi Ogbedeleto (s5131337@bournemouth.ac.uk)\n",
    "- Anne Rutherford (s5130945@bournemouth.ac.uk)\n",
    "- Ben Snow (bsnow@bournemouth.ac.uk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9aen2dL2Wjl"
   },
   "source": [
    "## Introduction and problem definition\n",
    "\n",
    "A Cardiotocography (CTG) is a scan used by medical professionals to measure the foetal heartrate and mother's uterine contractions during pregnancy. CTG scans are performed to gain insight into the wellbeing of the unborn foetus.\n",
    "\n",
    "In this project, an attempt is made to create a three class, neural network classifier to identify foetal status from a data set of diagnostic features. The status of the foetus is either N, S or P: Normal, Suspect or Pathologic. The dataset includes information from 2126 Cardiotocograms that measure foetal heartrate and uterine contractions. The dataset can be found [here.](https://archive.ics.uci.edu/ml/datasets/cardiotocography)\n",
    "\n",
    "Hypothesis: A multilayer perceptron classifier's performance measured by sensitivity and precision on the 'NSP' class in the CTG dataset is affected by the activation function in the hidden layers.\n",
    "\n",
    "- Null hypothesis H<sub>0</sub> : Not enough evidence to support the hypothesis.\n",
    "\n",
    "- Alternative hypothesis H<sub>1</sub> : Evidence found indicating the hypothesis is true.\n",
    "\n",
    "- The null hypothesis will be tested at the 5% significance level.\n",
    "\n",
    "Accuracy is not a good performance measure for an imbalanced datset as simply predicting all babies as normal will give high accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbdg89nMw4Hi"
   },
   "source": [
    "**Performance metrics**. Sensitivity (also known as recall) is a measure we use as it measures the extent to which we avoid false negatives. This measure has been chosen as it is important to avoid missing babies who are pathologic or abnormal, and each false negative represents a pathologic/abnormal baby missed by the classifier.\n",
    "$$Sensitivity = \\frac{Tp}{Tp+Fn}$$\n",
    "Precision is another measure of performance which measures the proportion of predicted positive values that were actually positive. This measures the extent to which we avoid false positives. This is important as we would like our model not to miss sick babies (sensitivity) but also provide good predictions, we don't want the model to be overcautious and predict every baby is pathologic/abnormal. In practical terms if the model is not precise it will be hard to use as medical staff will start to ignore predictions if there are too many false positives.\n",
    " $$Precision = \\frac{Tp}{Tp+Fp}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LWOt7EJ6TFOj"
   },
   "source": [
    "### Importing useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:09.485394Z",
     "start_time": "2020-03-05T23:13:39.478288Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "APb8IZ7cA7lf"
   },
   "outputs": [],
   "source": [
    "import numpy as np                                     # linear algebra\n",
    "import pandas as pd                                    # data processing\n",
    "from   pandas import DataFrame, read_csv               # data structures and csv reading\n",
    "import matplotlib.pyplot as plt                        # for plotting\n",
    "import tensorflow as tf                                # dataflow programming\n",
    "from   tensorflow import keras                         # neural networks API\n",
    "from   sklearn.model_selection import train_test_split # dataset splitting\n",
    "from   imblearn.over_sampling import ADASYN            # for oversampling\n",
    "import plotly.graph_objects as go                      # for data visualisation\n",
    "import plotly.io as pio                                # to set shahin plot layout\n",
    "import os\n",
    "from sklearn import preprocessing                      # for standardisation of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lP_7ZCaYw6xA"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L68F-CUOxF9A"
   },
   "source": [
    "### Reading data into appropriate structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rpmTTZrMFGMZ"
   },
   "source": [
    "After examining the CTG.xls dataset in Microsoft Excel it was found that there were some null columns and missing data. In the following cell data is read in from the dataset omiting null columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:27.432200Z",
     "start_time": "2020-03-05T23:14:09.488416Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "vLC3GnYUA7lk"
   },
   "outputs": [],
   "source": [
    "### specification of data location ###\n",
    "url_dataset = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00193/CTG.xls\"\n",
    "\n",
    "### Detection and removal of NaN collumns and rows ###\n",
    "df_data     =  pd.read_excel(url_dataset, sheet_name=\"Data\", header=1)                   # reading from 'data' sheet in the xls flie to a dataframe\n",
    "first_row_with_all_NaN = df_data[df_data.isnull().all(axis=1) == True].index.tolist()[0] # find first fully null row\n",
    "df_data = df_data.loc[0:first_row_with_all_NaN-1]                                        # remove any rows after the first all null row\n",
    "df_data = df_data.dropna(axis=1,how='all')                                               # remove any null collumns\n",
    "\n",
    "### Reading 'Raw Data' sheet cleaning ###\n",
    "df_raw_data = pd.read_excel(url_dataset, sheet_name=\"Raw Data\", header=1)\n",
    "df_raw_data = df_raw_data.dropna()\n",
    "df_raw_data=df_raw_data.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9W1J6vMXEgMS"
   },
   "source": [
    "## ***Data imbalance***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-3u6lnJWEpp4"
   },
   "source": [
    "It can be seen from the graph below that the 'NSP' class is imbalanced. There is a 78% data imbalance in favour of class 1. Training a model with this dataset can cause the model to learn mainly from the majority class. This can also lead to overfitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:28.147980Z",
     "start_time": "2020-03-05T23:14:27.433200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "DCCBgs0FA7lp",
    "outputId": "9789857d-81a2-4d5b-c246-85ad686f0fe7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df_data['NSP'].value_counts().plot.bar()   # defining a bar plot of the number of occurances of a given class\n",
    "ax.set_xlabel(\"NSP class\")                      # axis labels and plot title\n",
    "ax.set_ylabel(\"Number of occurances\")\n",
    "ax.set_title(\"Class imbalance of 'NSP' data\")\n",
    "no_class_one = df_data['NSP'].value_counts(0)\n",
    "total = no_class_one[1.0] + no_class_one[2.0] + no_class_one[3.0]\n",
    "imbalance_percent = round(((no_class_one[1.0]*100)/(total)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LAWcd0fOMzR"
   },
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G67_99E4MEPN"
   },
   "source": [
    "Standardising data enables data comparison on different scales and centre around 0, mean = 0, standard dev = 1, normalising means outliers can distort data.\n",
    "\n",
    "  This is a mapping of data to the unit gaussian distribution relevant due to the differing ranges of input data across the features (e.g. baseline value goes from 106-160 whereas mean value of short term variability (MTSV) ranges from 0.2-7) This technique is known to increase learning effectiveness when training Neural Networks's https://bit.ly/2DouAxm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:28.291179Z",
     "start_time": "2020-03-05T23:14:28.148977Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qaNRlD7HA7lt"
   },
   "outputs": [],
   "source": [
    "columns = ['LB', 'AC.1', 'FM.1', 'UC.1', 'DL.1', 'DS.1', 'DP.1', 'ASTV',        # defining the list of features used by an expert to determine the 'NSP' class\n",
    "           'MSTV', 'ALTV', 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros',\n",
    "           'Mode', 'Mean', 'Median', 'Variance', 'Tendency']\n",
    "\n",
    "labels_pre_split = df_data['NSP']              # defining 'NSP' labels into a data frame (prior to test/train separation)\n",
    "features_pre_split = df_data[columns]          # defining features\n",
    "\n",
    "### Standardisation of feature data ###\n",
    "scaler = preprocessing.StandardScaler()        # defining a scaler object on which to project standardised data\n",
    "scaled_feature_data = scaler.fit_transform(features_pre_split)\n",
    "features_pre_split = pd.DataFrame(scaled_feature_data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAMJkdSaOpAj"
   },
   "source": [
    "### Splitting into training, validation and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcGBJy3zBoLV"
   },
   "source": [
    "In order to reduce the effects of this data imbalance a popular upsampling technique called ADAptive SYNthetic oversampling, ADASYN, is used. ADASYN uses the minority classes in a dataset and to generate new, similar data for those classes.\n",
    "\n",
    "Oversampling is prefered to undersampling in this experiment due to the small number of datapoints available in the CTG dataset. Also undersampling may lead to data loss which is a problem due to scarcity of data from group 3. Oversampling restores balance between the classes shown in the bar chart.\n",
    "\n",
    "Before implementing ADASYN it is necessary to first split the dataset into training, validation and testing datasets. This is because validation and testing data must be real world data that has not been synthetically generated to give an objective measure of performance.\n",
    "\n",
    "First data is split 70:30 into training and testing sets. The testing set is then metaphorically 'locked away' to prevent it ever being used for training. Once the test data has been used it becomes part of the modelling process introducing the likelihood of the model being overfitted and losing predictive power and being less able to genaralise to eal life data. \n",
    "\n",
    "After this, the training data is split 70:30 into training and validation data. The validation data was available to use for testing any amended models and avoid using the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:28.642003Z",
     "start_time": "2020-03-05T23:14:28.292113Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "B7-9LeHROT3e",
    "outputId": "dd12b9b8-e4b9-406a-bb18-e0fa49d37a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Effect of ADASYN oversampling on class imbalance')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Extracting testing and training data ###\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features_pre_split,labels_pre_split,test_size=0.3,random_state=0)   # 70/30 training/testing splitting performed randomly\n",
    "\n",
    "features_true_train, features_validation, labels_true_train, labels_validation = train_test_split(features_train,labels_train,test_size=0.3,random_state=0) # 70/30 training/validation splitting of the initial training data\n",
    "\n",
    "features_resampled_true_train, labels_resampled_true_train = ADASYN().fit_sample(features_true_train, labels_true_train)  # oversampling of the training dataset\n",
    "\n",
    "features_resampled_true_train = pd.DataFrame(features_resampled_true_train, columns=[columns])    # storing features and labels in dataframes\n",
    "labels_resampled_true_train = pd.DataFrame(labels_resampled_true_train, columns=['NSP'])\n",
    "\n",
    "### Plot to show the effect of oversampling e.g. restored class balance. ###\n",
    "ax = labels_resampled_true_train['NSP'].value_counts().plot.bar()\n",
    "ax.set_xlabel(\"NSP class\")\n",
    "ax.set_ylabel(\"Number of occurances\")\n",
    "ax.set_title(\"Effect of ADASYN oversampling on class imbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZOmChv7mS0Bd"
   },
   "source": [
    "### One hot encoding of labelled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CCcsUMteu9L5"
   },
   "source": [
    "Since the data in the NSP column is categorical we need to convert it into an integer form so it can be used in neural network training. This is called one hot encoding and is performed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:28.653970Z",
     "start_time": "2020-03-05T23:14:28.643000Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0k9keJycA7lu"
   },
   "outputs": [],
   "source": [
    "## training cat codes\n",
    "labels_cat_codes_train = labels_resampled_true_train['NSP'].astype('category').cat.codes        # convert the NSP to categories (instead of doubles)\n",
    "labels_cat_one_hot_train = keras.utils.to_categorical(labels_cat_codes_train,num_classes=None)  # one hot encoding\n",
    "\n",
    "## validation cat codes\n",
    "labels_cat_codes_val = labels_validation.astype('category').cat.codes\n",
    "labels_cat_one_hot_val = keras.utils.to_categorical(labels_cat_codes_val,num_classes=None)\n",
    "\n",
    "## testing cat codes\n",
    "labels_cat_codes_test = labels_test.astype('category').cat.codes\n",
    "labels_cat_one_hot_test = keras.utils.to_categorical(labels_cat_codes_test,num_classes=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sofgL0p7w8gT"
   },
   "source": [
    "## ***Model Building***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3arm4f-RTDw"
   },
   "source": [
    "## Perceptron model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9NUg9M1i_bR3"
   },
   "source": [
    "Here a function to create simple multilayer perceptrons optimised by the ADAM optimiser is constructed. This ensures that each of the neural networks created have the same architecture. A simple architecture is used to keep compilation, training and testing times low.\n",
    "The exact same architecture for each examined network will be used. A diagram of this can be seen here: ![Hello](https://i.imgur.com/0j8kPkZ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:28.768489Z",
     "start_time": "2020-03-05T23:14:28.654968Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7-TdBTTCnD-W"
   },
   "outputs": [],
   "source": [
    "def perceptron_builder(input_dim_, output_dim_, number_hidden_layers_, hidden_activation_, output_activation_):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Dense(21, input_shape=(input_dim_,), activation = hidden_activation_))\n",
    "  for i in range (number_hidden_layers_-1):\n",
    "    model.add(keras.layers.Dense(21, activation = hidden_activation_))\n",
    "  \n",
    "  model.add(keras.layers.Dense(3, activation = output_activation_))\n",
    "  model.compile(keras.optimizers.Adam(), 'categorical_crossentropy', metrics=['accuracy'],)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGELi1u4RSlB"
   },
   "source": [
    "## Training and validation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PazedqzR_3of"
   },
   "source": [
    "Models will be trained with the same training data and then will be validated with the same validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:28.933490Z",
     "start_time": "2020-03-05T23:14:28.774467Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "abP-HF1Fw_58"
   },
   "outputs": [],
   "source": [
    "def model_train(model_, input_data_, labelled_data_, epochs_, verbose_):\n",
    "  return model_.fit(input_data_, labelled_data_, epochs = epochs_, verbose = verbose_)\n",
    " \n",
    "def model_validate(model_, test_features_, test_labels_):\n",
    "  return model_.evaluate(test_features_, test_labels_)[1]\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iaOXchh9RiL7"
   },
   "source": [
    "## Generation of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vB5Vapy8__nA"
   },
   "source": [
    "Three different activation functions are specified: tanh, relu & sigmoid. Tanh and sigmoid were chosen for their step like features with different gradients within limits and relu as it tends to activate more sparsely and be more computationally efficient. The independent variable, therefore, in this experiment is the activation function in the hidden layers of the neural networks. Models are generated, trained and stored together in a data dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hYHvSaXnvQMI"
   },
   "source": [
    "Sampling: for our experiment we have chosen a sample size of 10 to calculate mean sensitivity and precision rates as this is commonly used since it is high enough to give a reasonable value without taking too long. We ideally would use 30 but this caused the notebook to crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-05T23:14:29.073586Z",
     "start_time": "2020-03-05T23:14:28.938476Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7ylZGbsaugTn"
   },
   "outputs": [],
   "source": [
    "activation_funs = ['tanh', 'relu', 'sigmoid'] # edit this list to change the number of activation functions (e.g. number of models to train)\n",
    "number_of_models = 11\n",
    "## Initialising data dictionary\n",
    "dict_of_perceptrons={};\n",
    "for i in activation_funs:\n",
    "    dict_of_perceptrons[i]={}\n",
    "for i in activation_funs:\n",
    "  for j in range (1,number_of_models):\n",
    "    dict_of_perceptrons[i][j]={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:40.492Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KBuq3MLuorxJ",
    "outputId": "e3d9a138-e338-4b84-8f0e-6883bbc81b09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 3s 1ms/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 120us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 124us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 134us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 119us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 122us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 115us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357s - loss: 1.1921e-07 - accuracy: 0.34\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 119us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 119us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357s - loss: 1.1921e-07 - accuracy: 0.33\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 115us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 113us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 113us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 1s 269us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 126us/sample - loss: 1.0986 - accuracy: 0.3155\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 123us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0988 - accuracy: 0.3188\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3336\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3324\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3204\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3324\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3237\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3287\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 126us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3159\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 115us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.0987 - accuracy: 0.3316\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3295\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3316\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0986 - accuracy: 0.3266\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 118us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3163\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0986 - accuracy: 0.3204\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3320\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3139\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0987 - accuracy: 0.3320\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3196\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 120us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 124us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 122us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.0986 - accuracy: 0.3311\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3200\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0986 - accuracy: 0.3283\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3278\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3254\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0986 - accuracy: 0.3266\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3369\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3192\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3151\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 115us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0986 - accuracy: 0.3348\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 179us/sample - loss: 1.0988 - accuracy: 0.3283\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3192\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0986 - accuracy: 0.3246\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 119us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3311\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0986 - accuracy: 0.3303\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3303\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0986 - accuracy: 0.3250\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.0986 - accuracy: 0.3266\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 113us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0986 - accuracy: 0.3217\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0986 - accuracy: 0.3180\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3332\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3340\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.0987 - accuracy: 0.3204\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3344\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3262\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3114\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0988 - accuracy: 0.3209\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3320\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3340\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3320\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - ETA: 0s - loss: 1.0985 - accuracy: 0.34 - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3340\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3184\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3365\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0988 - accuracy: 0.3200\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.3229\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.0986 - accuracy: 0.3233\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 113us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3204\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3340\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.32 - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3188\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3365\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3221\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3353\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3307\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3196\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 126us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0988 - accuracy: 0.3348\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0986 - accuracy: 0.3307\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0986 - accuracy: 0.3332\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.3225\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.3324\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0986 - accuracy: 0.3283\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.3278\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0987 - accuracy: 0.3176\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0986 - accuracy: 0.3336\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0987 - accuracy: 0.3192\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3344\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3159\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0986 - accuracy: 0.3262\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3139\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.3299\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0986 - accuracy: 0.3250\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0986 - accuracy: 0.3307\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 113us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3324\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.3340\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.0987 - accuracy: 0.3192\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3250s - loss: 1.0987 - accuracy: 0.31\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0988 - accuracy: 0.3237\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0987 - accuracy: 0.3377\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 123us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 120us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 122us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0988 - accuracy: 0.3233\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.0986 - accuracy: 0.3221\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 129us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 120us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 126us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.0986 - accuracy: 0.3262\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0987 - accuracy: 0.3188\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.0986 - accuracy: 0.3266\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 113us/sample - loss: 1.0987 - accuracy: 0.3332\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0988 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0986 - accuracy: 0.3262\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0986 - accuracy: 0.3303\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0986 - accuracy: 0.3287\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3340\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0988 - accuracy: 0.3172\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.3233\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0987 - accuracy: 0.3155\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0986 - accuracy: 0.3241\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.0986 - accuracy: 0.3254\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 130us/sample - loss: 1.0986 - accuracy: 0.3299\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3188\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 120us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 120us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3200\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.0988 - accuracy: 0.3184\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0988 - accuracy: 0.3229\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3204\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0988 - accuracy: 0.3188\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3151\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3192\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3167\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3204\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0986 - accuracy: 0.3254\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0986 - accuracy: 0.3278\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0986 - accuracy: 0.3361\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.0986 - accuracy: 0.3303\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3324\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0986 - accuracy: 0.3348\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0986 - accuracy: 0.3196\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3357s - loss: 1.0991 - accuracy\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0986 - accuracy: 0.3233\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0986 - accuracy: 0.3246\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0988 - accuracy: 0.3196\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3336\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3159\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.0987 - accuracy: 0.3316\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3336\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0987 - accuracy: 0.3184\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 119us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.0986 - accuracy: 0.3221\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3147\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3316\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 123us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 127us/sample - loss: 1.0987 - accuracy: 0.3336\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 149us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.0987 - accuracy: 0.3163\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 115us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.0986 - accuracy: 0.3278\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3361\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3336\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3320\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0986 - accuracy: 0.3241\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3320\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3139\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.0986 - accuracy: 0.3283\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.3369\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3262\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.3229\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0986 - accuracy: 0.3229\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3225\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3106\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357s - loss: 1.0986 - accuracy: 0.\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3069\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3336\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3237\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3180\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3295\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3324\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3204\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3258\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3225\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3328\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3200\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3110\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0987 - accuracy: 0.3332\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3348\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3163\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3320\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3188\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3266\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0988 - accuracy: 0.3204\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3180\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3332\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3328\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3130\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0988 - accuracy: 0.3246\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3353\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3204\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3316\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3320\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3394\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0988 - accuracy: 0.3110\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3324\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3320\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3320\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3241\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3287\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3311\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3102\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3118\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3303\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3332\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3340\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0988 - accuracy: 0.3320\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3196\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3188\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3163\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3093\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3270\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.0986 - accuracy: 0.3229\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3188\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3237\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0988 - accuracy: 0.3213\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3204\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0988 - accuracy: 0.3204\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3258\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3377\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0986 - accuracy: 0.3254\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3143\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3254\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3324\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0988 - accuracy: 0.3254\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3369\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3241\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3229s - loss: 1.0987 - accuracy: 0.31\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3147\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3299\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3303\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3344\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3196\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0988 - accuracy: 0.3184\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3258\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3295\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3303\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3209\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3369\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0988 - accuracy: 0.3200\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3167\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3320\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3172\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3303\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3361\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3266\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3278\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.0986 - accuracy: 0.3262\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0987 - accuracy: 0.3172\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0986 - accuracy: 0.3270\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3274\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3147\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3258\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3258\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.0988 - accuracy: 0.3246\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0986 - accuracy: 0.3258\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3291\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3225\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0988 - accuracy: 0.3303\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3188\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3336\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3348\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3336\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3307\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0986 - accuracy: 0.3221\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.0988 - accuracy: 0.3274\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.0986 - accuracy: 0.3274\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0988 - accuracy: 0.3213\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3237\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0988 - accuracy: 0.3217\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3328\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3283\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3246\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.0987 - accuracy: 0.3311\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3147\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3373\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3262\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.0986 - accuracy: 0.3348\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0986 - accuracy: 0.3320\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3250\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3180\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3348\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3114\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3291\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3287\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3217\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3180\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3180\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3270\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0986 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3213\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0988 - accuracy: 0.3357s - loss: 1.0985 - accuracy: \n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.0986 - accuracy: 0.3221\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.0986 - accuracy: 0.3159\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0986 - accuracy: 0.3258\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3316\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0986 - accuracy: 0.3254\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3241\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3258\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3209\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0986 - accuracy: 0.3278\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3233\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.0987 - accuracy: 0.3254\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3278\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3299\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3373\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.0987 - accuracy: 0.3266\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3381\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3246\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.0987 - accuracy: 0.3221\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.0987 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 157us/sample - loss: 1.1383 - accuracy: 0.3303\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.33 - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1028 - accuracy: 0.3217\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1142 - accuracy: 0.3172\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1023 - accuracy: 0.3258\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 77us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 119us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 124us/sample - loss: 1.1031 - accuracy: 0.3229\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 120us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 135us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 109us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 140us/sample - loss: 1.1297 - accuracy: 0.3258\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 106us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 132us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 132us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 113us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 122us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 110us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 98us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 126us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 119us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 112us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 116us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 128us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 131us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 124us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 139us/sample - loss: 1.1005 - accuracy: 0.3250\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 92us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 111us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 137us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 117us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 119us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 135us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 124us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 133us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 162us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357s - loss: 1.1921e-07 - accuracy: 0.33\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 99us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 121us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 97us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 102us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1072 - accuracy: 0.3369\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 96us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 93us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 101us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 72/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 73/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 74/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 75/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 76/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 78/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 79/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 80/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 81/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 82/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 83/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 84/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 85/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 86/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 87/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 88/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 89/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 90/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 91/100\n",
      "2431/2431 [==============================] - 0s 77us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 92/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 93/100\n",
      "2431/2431 [==============================] - 0s 78us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 94/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 95/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 96/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 97/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 98/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 99/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 100/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2431 samples\n",
      "Epoch 1/100\n",
      "2431/2431 [==============================] - 0s 108us/sample - loss: 1.1098 - accuracy: 0.3241\n",
      "Epoch 2/100\n",
      "2431/2431 [==============================] - 0s 79us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 3/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357s - loss: 1.1921e-07 - accuracy: 0.\n",
      "Epoch 4/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 5/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 6/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 7/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 8/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 9/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 10/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 12/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 13/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 14/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 15/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 16/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 17/100\n",
      "2431/2431 [==============================] - 0s 105us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 19/100\n",
      "2431/2431 [==============================] - 0s 103us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 20/100\n",
      "2431/2431 [==============================] - 0s 90us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 21/100\n",
      "2431/2431 [==============================] - 0s 104us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 22/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 23/100\n",
      "2431/2431 [==============================] - 0s 95us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 24/100\n",
      "2431/2431 [==============================] - 0s 89us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 25/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 26/100\n",
      "2431/2431 [==============================] - 0s 88us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 27/100\n",
      "2431/2431 [==============================] - 0s 107us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 28/100\n",
      "2431/2431 [==============================] - 0s 100us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 29/100\n",
      "2431/2431 [==============================] - 0s 91us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 30/100\n",
      "2431/2431 [==============================] - 0s 86us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 31/100\n",
      "2431/2431 [==============================] - 0s 94us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 32/100\n",
      "2431/2431 [==============================] - 0s 114us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 33/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 34/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 35/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 36/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 37/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 38/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 39/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 40/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 41/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 42/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 43/100\n",
      "2431/2431 [==============================] - 0s 87us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 44/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 45/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 46/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 47/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 48/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 49/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 50/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 51/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 52/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 53/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 54/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 55/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 56/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 57/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 58/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 59/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 60/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 61/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 62/100\n",
      "2431/2431 [==============================] - 0s 82us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 63/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 64/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357s - loss: 1.1921e-07 - accuracy: \n",
      "Epoch 65/100\n",
      "2431/2431 [==============================] - 0s 84us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 66/100\n",
      "2431/2431 [==============================] - 0s 83us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 67/100\n",
      "2431/2431 [==============================] - 0s 80us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 68/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 69/100\n",
      "2431/2431 [==============================] - 0s 85us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 70/100\n",
      "2431/2431 [==============================] - 0s 81us/sample - loss: 1.1921e-07 - accuracy: 0.3357\n",
      "Epoch 71/100\n",
      "1312/2431 [===============>..............] - ETA: 0s - loss: 1.1921e-07 - accuracy: 0.34"
     ]
    }
   ],
   "source": [
    "for i in range(len(activation_funs)):\n",
    "  for j in range(1,number_of_models):\n",
    "    perceptron = perceptron_builder(21, 3, 4, activation_funs[i], 'softmax')               # building a perceptron model\n",
    "    model_train(perceptron, features_resampled_true_train, labels_cat_one_hot_train, 100, 1) # training the perceptron\n",
    "    if i == 0:\n",
    "      function_name = 'tanh'\n",
    "    elif i == 1:\n",
    "      function_name = 'relu'\n",
    "    elif i == 2:\n",
    "      function_name = 'sigmoid'\n",
    "    dict_of_perceptrons[function_name][j] = perceptron ## storing the perceptron models in a data dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YlkJtSUWRsiM"
   },
   "source": [
    "## Creating predictions for the test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jabh4k4sAwXQ"
   },
   "source": [
    "After training, predictions are generated for the testing data to give a probability for each class. These probabilities are then rounded so that the highest probability is chosen to be the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:40.607Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "LucZ9R9-eN2m"
   },
   "outputs": [],
   "source": [
    "## Initialising data dictionary\n",
    "dict_of_predictions={};\n",
    "dict_of_rounded_predictions = {};\n",
    "for i in activation_funs:\n",
    "    dict_of_predictions[i]={}\n",
    "    dict_of_rounded_predictions[i]={}\n",
    "for i in activation_funs:\n",
    "  for j in range (1,number_of_models):\n",
    "    dict_of_predictions[i][j]={}\n",
    "    dict_of_rounded_predictions[i][j]={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:40.610Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "ROqAC2KUp9fJ",
    "outputId": "62481ad1-f033-422c-e3a6-dbc17fda4831"
   },
   "outputs": [],
   "source": [
    "for j in range (1, number_of_models):\n",
    "  for i in activation_funs:\n",
    "    dict_of_predictions[i][j] = dict_of_perceptrons[i][j].predict(features_test, batch_size=None, verbose = 1) # storing predictions for each model in an array\n",
    "    dict_of_rounded_predictions[i][j] = dict_of_perceptrons[i][j].predict_classes(features_test) # Rounding predictions to give a definite class instead of a probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quHlxXhyNC97"
   },
   "source": [
    "# Experimental design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8m4I4tnNMg4"
   },
   "source": [
    "A diagram of the classes and groups for the experiments can be seen in the diagram below : ![Hello](https://i.imgur.com/ndqOlKV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6M5_S3VKHycC"
   },
   "source": [
    "### Grouped class comparisons\n",
    "\n",
    "Accuracy is not  good metric for model performance due to the imbalanced nature of the dataset. If we simply predicted all babies to be class 1 we would be highly accurate but the model would not be useful.\n",
    "Here the predictions are grouped into confusion matrices showing normal vs abnormal where abnormal includes suspect and pathologic. The classes are also grouped into pathologic vs non-pathologic, with non pathologic containing suspect and normal. This relates to class 1 vs classes 2 & 3 and class 1 & 2 vs class 3. This is because we want to avoid false negative instances where pathologic babies are missed, and we also want to miss false negatives of pathologic and suspect babies. We would ask experts which of these is most important as it maybe suspect babies tend to develop into pathologic babies, or that suspect babies tend not to develop into pathologic babies in most instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:40.830Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "3NTvpikavbcm"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "dict_compare_predicts = copy.deepcopy(dict_of_predictions)\n",
    "dict_one_vs_rest_pred = copy.deepcopy(dict_of_rounded_predictions) # This holds the rounded predicitons for class 1 vs 2 & 3\n",
    "dict_rest_vs_three_pred = copy.deepcopy(dict_of_rounded_predictions) # This holds the rounded predictions for classes 1 & 2 vs 3\n",
    "\n",
    "for k in activation_funs:\n",
    "  for j in range (1,number_of_models):\n",
    "    for i in range (len(dict_of_rounded_predictions[k][j])):\n",
    "      if (dict_compare_predicts[k][j][i][0]>0.5):\n",
    "        dict_one_vs_rest_pred[k][j][i] = 0\n",
    "      else:\n",
    "        dict_one_vs_rest_pred[k][j][i] = 2\n",
    "\n",
    "  for j in range(1, number_of_models):\n",
    "    for i in range (len(dict_of_rounded_predictions[k][j])):\n",
    "      if (dict_compare_predicts[k][j][i][2]>0.5):\n",
    "        dict_rest_vs_three_pred[k][j][i] = 0\n",
    "      else:\n",
    "        dict_rest_vs_three_pred[k][j][i] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fhuASqyIjkD"
   },
   "source": [
    "Here the test and validation labels are split into normal vs abnormal and pathologic vs non-pathologic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:40.885Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2ToZL1t3EBiP"
   },
   "outputs": [],
   "source": [
    "numpy_labels_val = labels_validation.to_numpy()\n",
    "val_labels_ref = numpy_labels_val\n",
    "test_labels_ref = labels_test.to_numpy()\n",
    "\n",
    "val_labels_one_vs_rest = np.copy(val_labels_ref)\n",
    "test_labels_one_vs_rest = np.copy(test_labels_ref)\n",
    "val_labels_rest_vs_three = np.copy(val_labels_ref)\n",
    "test_labels_rest_vs_three = np.copy(test_labels_ref)\n",
    "\n",
    "for i in range(len(val_labels_one_vs_rest)):\n",
    "  if (val_labels_one_vs_rest[i] == 2) | (val_labels_one_vs_rest[i] == 3):\n",
    "    val_labels_one_vs_rest[i] = 3\n",
    "  else:\n",
    "    val_labels_one_vs_rest[i] = 1\n",
    "\n",
    "for i in range(len(test_labels_one_vs_rest)):\n",
    "  if (test_labels_one_vs_rest[i] == 2) | (test_labels_one_vs_rest[i] == 3):\n",
    "    test_labels_one_vs_rest[i] = 3\n",
    "  else:\n",
    "    test_labels_one_vs_rest[i] = 1\n",
    "\n",
    "for i in range(len(val_labels_rest_vs_three)):\n",
    "  if (val_labels_rest_vs_three[i] == 1) | (val_labels_rest_vs_three[i] == 2):\n",
    "    val_labels_rest_vs_three[i] = 1\n",
    "  else:\n",
    "    val_labels_rest_vs_three[i] = 3\n",
    "\n",
    "for i in range(len(test_labels_rest_vs_three)):\n",
    "  if (test_labels_rest_vs_three[i] == 1) | (test_labels_rest_vs_three[i] == 2):\n",
    "    test_labels_rest_vs_three[i] = 1\n",
    "  else:\n",
    "    test_labels_rest_vs_three[i] = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ADAwTBfXI_ki"
   },
   "source": [
    "### Confusion matrix for normal vs abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:40.941Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rx29dQX83k3e"
   },
   "outputs": [],
   "source": [
    "## initialising data dictionaries for confusion matricies\n",
    "dict_of_cm_temp_one_vs_rest = {};\n",
    "dict_of_cm_real_one_vs_rest = {};\n",
    "dict_of_cm_temp_rest_vs_three = {};\n",
    "dict_of_cm_real_rest_vs_three = {};\n",
    "for i in activation_funs:\n",
    "    dict_of_cm_temp_one_vs_rest[i]={}\n",
    "    dict_of_cm_real_one_vs_rest[i]={}\n",
    "    dict_of_cm_temp_rest_vs_three[i]={}\n",
    "    dict_of_cm_real_rest_vs_three[i]={}\n",
    "\n",
    "for i in activation_funs:\n",
    "  for j in range (1,number_of_models):\n",
    "    dict_of_cm_temp_one_vs_rest[i][j]=[0,0,0]\n",
    "    dict_of_cm_real_one_vs_rest[i][j]=[0,0,0]\n",
    "    dict_of_cm_temp_rest_vs_three[i][j]=[0,0,0]\n",
    "    dict_of_cm_real_rest_vs_three[i][j]=[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:40.944Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "QBAgwZt8qMlS",
    "outputId": "dbee0e36-c663-4f0c-9ee5-f2a9d6aaf435"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "for i in activation_funs:    # Looping to reformat the confusion matrices\n",
    "  for j in range (1, number_of_models):\n",
    "    dict_of_cm_temp_one_vs_rest[i][j] = confusion_matrix(test_labels_one_vs_rest, dict_one_vs_rest_pred[i][j]) # Creating the temporary confusion matrices\n",
    "    dict_of_cm_real_one_vs_rest[i][j] = dict_of_cm_temp_one_vs_rest[i][j][1:4,0:3]\n",
    "    dict_of_cm_real_one_vs_rest[i][j] = dict_of_cm_real_one_vs_rest[i][j][[0,2]]\n",
    "    dict_of_cm_real_one_vs_rest[i][j] = dict_of_cm_real_one_vs_rest[i][j][:,[0,2]]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "conf_matrix_one_vs_rest = sns.heatmap((dict_of_cm_real_one_vs_rest['tanh'][1]), annot=True, fmt='0.5g', cmap = \"YlGnBu\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_title(\"Perceptron model 1 with activation function tanh for normal vs abnormal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QlkCWwmFJs1_"
   },
   "source": [
    "### Confusion matrix for pathologic vs non pathologic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:40.994Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "JuMRcTy7pZfU",
    "outputId": "b110b25d-0371-4237-a628-2f99c5873c3e"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "\n",
    "for i in activation_funs:    # Looping to reformat the confusion matrices\n",
    "  for j in range (1, number_of_models):\n",
    "    dict_of_cm_temp_rest_vs_three[i][j] = confusion_matrix(test_labels_rest_vs_three, dict_rest_vs_three_pred[i][j]) # Creating the temporary confusion matrices\n",
    "    dict_of_cm_real_rest_vs_three[i][j] = dict_of_cm_temp_rest_vs_three[i][j][1:4,:]\n",
    "    dict_of_cm_real_rest_vs_three[i][j] = dict_of_cm_real_rest_vs_three[i][j][[0,2]]\n",
    "    dict_of_cm_real_rest_vs_three[i][j][:,3] = dict_of_cm_real_rest_vs_three[i][j][:,0]\n",
    "    dict_of_cm_real_rest_vs_three[i][j] = dict_of_cm_real_rest_vs_three[i][j][:,[2,3]]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "conf_matrix_rest_vs_three = sns.heatmap((dict_of_cm_real_rest_vs_three['relu'][1]), annot=True, fmt='0.5g', cmap = \"YlGnBu\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_title(\"Perceptron model 1 with activation function relu for non pathologic vs pathologic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kpjfLe8kNBDF"
   },
   "source": [
    "### Calculation of performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCd8wGOgqpp3"
   },
   "source": [
    "#### Performance metrics for the normal vs abnormal problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.095Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "colab_type": "code",
    "id": "omqHoC9_OoCB",
    "outputId": "d93aac2e-8542-4998-f294-98802906d60d"
   },
   "outputs": [],
   "source": [
    "list_of_attributes_one_vs_rest = ['Tp_normal', 'Tp_abnormal', 'Tn_normal', 'Tn_abnormal', 'Fp_normal',\n",
    "                      'Fp_abnormal', 'Fn_normal', 'Fn_abnormal', 'Sensitivity_normal', 'Sensitivity_abnormal',\n",
    "                      'Precision_normal', 'Precision_abnormal', 'Specificity_normal', 'Specificity_abnormal',\n",
    "                      'F_measure_normal', 'F_measure_abnormal', 'Accuracy']\n",
    "\n",
    "## Initialising data dictionary\n",
    "dict_of_metrics_one_vs_rest={};\n",
    "for i in activation_funs:\n",
    "    dict_of_metrics_one_vs_rest[i]={}\n",
    "for i in activation_funs:\n",
    "  for j in range (1,number_of_models):\n",
    "    dict_of_metrics_one_vs_rest[i][j] = {}\n",
    "\n",
    "for i in activation_funs:\n",
    "  for j in range (1,number_of_models):\n",
    "    for k in list_of_attributes_one_vs_rest:\n",
    "      dict_of_metrics_one_vs_rest[i][j][k]={}\n",
    "\n",
    "decimal_places = 4 ## Define the number of decimal points to round the metrics to\n",
    "\n",
    "for i in activation_funs:\n",
    "  for j in range (1, number_of_models):\n",
    "    ## True positives\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Tp_normal'] = dict_of_cm_real_one_vs_rest[i][j][0][0]\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Tp_abnormal'] = dict_of_cm_real_one_vs_rest[i][j][1][1]\n",
    "    ## True negatives\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Tn_normal'] = dict_of_cm_real_one_vs_rest[i][j][1][1]\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Tn_abnormal'] = dict_of_cm_real_one_vs_rest[i][j][0][0]\n",
    "    ## False positives\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Fp_normal'] = dict_of_cm_real_one_vs_rest[i][j][1][0]\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Fp_abnormal'] = dict_of_cm_real_one_vs_rest[i][j][0][1]\n",
    "    ## False negatives\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Fn_normal'] = dict_of_cm_real_one_vs_rest[i][j][0][1]\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Fn_abnormal'] = dict_of_cm_real_one_vs_rest[i][j][1][0]\n",
    "\n",
    "    ## Sensitivity\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Sensitivity_normal'] = round(dict_of_metrics_one_vs_rest[i][j]['Tp_normal']/(dict_of_metrics_one_vs_rest[i][j]['Tp_normal']+dict_of_metrics_one_vs_rest[i][j]['Fn_normal']),decimal_places)\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Sensitivity_abnormal'] = round(dict_of_metrics_one_vs_rest[i][j]['Tp_abnormal']/(dict_of_metrics_one_vs_rest[i][j]['Tp_abnormal']+dict_of_metrics_one_vs_rest[i][j]['Fn_abnormal']),decimal_places)\n",
    "\n",
    "    ## Precision\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Precision_normal']   = round(dict_of_metrics_one_vs_rest[i][j]['Tp_normal']/(dict_of_metrics_one_vs_rest[i][j]['Tp_normal']+dict_of_metrics_one_vs_rest[i][j]['Fp_normal']), decimal_places)\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Precision_abnormal']   = round(dict_of_metrics_one_vs_rest[i][j]['Tp_abnormal']/(dict_of_metrics_one_vs_rest[i][j]['Tp_abnormal']+dict_of_metrics_one_vs_rest[i][j]['Fp_abnormal']), decimal_places)\n",
    "    \n",
    "    ## Specificity\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Specificity_normal'] = round(dict_of_metrics_one_vs_rest[i][j]['Tn_normal']/(dict_of_metrics_one_vs_rest[i][j]['Tn_normal']+dict_of_metrics_one_vs_rest[i][j]['Fp_normal']), decimal_places)\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Specificity_abnormal'] = round(dict_of_metrics_one_vs_rest[i][j]['Tn_abnormal']/(dict_of_metrics_one_vs_rest[i][j]['Tn_abnormal']+dict_of_metrics_one_vs_rest[i][j]['Fp_abnormal']), decimal_places)\n",
    "      \n",
    "    ## F-measure\n",
    "    dict_of_metrics_one_vs_rest[i][j]['F_measure_normal']   = round((2*dict_of_metrics_one_vs_rest[i][j]['Sensitivity_normal']*dict_of_metrics_one_vs_rest[i][j]['Precision_normal'])/(dict_of_metrics_one_vs_rest[i][j]['Sensitivity_normal']+dict_of_metrics_one_vs_rest[i][j]['Precision_normal']), decimal_places)\n",
    "    dict_of_metrics_one_vs_rest[i][j]['F_measure_abnormal']   = round((2*dict_of_metrics_one_vs_rest[i][j]['Sensitivity_abnormal']*dict_of_metrics_one_vs_rest[i][j]['Precision_abnormal'])/(dict_of_metrics_one_vs_rest[i][j]['Sensitivity_abnormal']+dict_of_metrics_one_vs_rest[i][j]['Precision_abnormal']), decimal_places)\n",
    "    \n",
    "    ## Accuracy\n",
    "    dict_of_metrics_one_vs_rest[i][j]['Accuracy'] = round((dict_of_metrics_one_vs_rest[i][j]['Tp_normal']+ dict_of_metrics_one_vs_rest[i][j]['Tn_normal'])/(dict_of_metrics_one_vs_rest[i][j]['Tp_normal']+dict_of_metrics_one_vs_rest[i][j]['Fp_normal']+dict_of_metrics_one_vs_rest[i][j]['Tn_normal']+dict_of_metrics_one_vs_rest[i][j]['Fp_normal']), decimal_places)\n",
    "\n",
    "\n",
    "for x in dict_of_metrics_one_vs_rest:\n",
    "    print (\"\\033[4m\", x ,\"\\033[0m\", '\\n')\n",
    "    for y in dict_of_metrics_one_vs_rest[x]:\n",
    "      print (y,':',dict_of_metrics_one_vs_rest[x][y])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1uo9Lgsq4qQ"
   },
   "source": [
    "#### Performance metrics for the pathalogic vs non pathalogic problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.149Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "colab_type": "code",
    "id": "YM2UZhjaNU5R",
    "outputId": "5d696b00-d739-4f4f-e411-834fcd0e62a1"
   },
   "outputs": [],
   "source": [
    "list_of_attributes_rest_vs_three = ['Tp_non_pathalogic', 'Tp_pathalogic', 'Tn_non_pathalogic', 'Tn_pathalogic', 'Fp_non_pathalogic',\n",
    "                      'Fp_pathalogic', 'Fn_non_pathalogic', 'Fn_pathalogic', 'Sensitivity_non_pathalogic', 'Sensitivity_pathalogic',\n",
    "                      'Precision_non_pathalogic', 'Precision_pathalogic', 'Specificity_non_pathalogic', 'Specificity_pathalogic',\n",
    "                      'F_measure_non_pathalogic', 'F_measure_pathalogic', 'Accuracy']\n",
    "\n",
    "## Initialising data dictionary\n",
    "dict_of_metrics_rest_vs_three={};\n",
    "for i in activation_funs:\n",
    "    dict_of_metrics_rest_vs_three[i]={}\n",
    "for i in activation_funs:\n",
    "  for j in range (1,number_of_models):\n",
    "    dict_of_metrics_rest_vs_three[i][j] = {}\n",
    "\n",
    "for i in activation_funs:\n",
    "  for j in range (1,number_of_models):\n",
    "    for k in list_of_attributes_rest_vs_three:\n",
    "      dict_of_metrics_rest_vs_three[i][j][k]={}\n",
    "\n",
    "decimal_places = 4 ## Define the number of decimal points to round the metrics to\n",
    "\n",
    "for i in activation_funs:\n",
    "  for j in range (1, number_of_models):\n",
    "    ## True positives\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Tp_non_pathalogic'] = dict_of_cm_real_rest_vs_three[i][j][0][0]\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Tp_pathalogic'] = dict_of_cm_real_rest_vs_three[i][j][1][1]\n",
    "    ## True negatives\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Tn_non_pathalogic'] = dict_of_cm_real_rest_vs_three[i][j][1][1]\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Tn_pathalogic'] = dict_of_cm_real_rest_vs_three[i][j][0][0]\n",
    "    ## False positives\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Fp_non_pathalogic'] = dict_of_cm_real_rest_vs_three[i][j][1][0]\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Fp_pathalogic'] = dict_of_cm_real_rest_vs_three[i][j][0][1]\n",
    "    ## False negatives\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Fn_non_pathalogic'] = dict_of_cm_real_rest_vs_three[i][j][0][1]\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Fn_pathalogic'] = dict_of_cm_real_rest_vs_three[i][j][1][0]\n",
    "\n",
    "    ## Sensitivity\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Sensitivity_non_pathalogic'] = round(dict_of_metrics_rest_vs_three[i][j]['Tp_non_pathalogic']/(dict_of_metrics_rest_vs_three[i][j]['Tp_non_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Fn_non_pathalogic']),decimal_places)\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Sensitivity_pathalogic'] = round(dict_of_metrics_rest_vs_three[i][j]['Tp_pathalogic']/(dict_of_metrics_rest_vs_three[i][j]['Tp_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Fn_pathalogic']),decimal_places)\n",
    "\n",
    "    ## Precision\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Precision_non_pathalogic']   = round(dict_of_metrics_rest_vs_three[i][j]['Tp_non_pathalogic']/(dict_of_metrics_rest_vs_three[i][j]['Tp_non_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Fp_non_pathalogic']), decimal_places)\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Precision_pathalogic']   = round(dict_of_metrics_rest_vs_three[i][j]['Tp_pathalogic']/(dict_of_metrics_rest_vs_three[i][j]['Tp_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Fp_pathalogic']), decimal_places)\n",
    "    \n",
    "    ## Specificity\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Specificity_non_pathalogic'] = round(dict_of_metrics_rest_vs_three[i][j]['Tn_non_pathalogic']/(dict_of_metrics_rest_vs_three[i][j]['Tn_non_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Fp_non_pathalogic']), decimal_places)\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Specificity_pathalogic'] = round(dict_of_metrics_rest_vs_three[i][j]['Tn_pathalogic']/(dict_of_metrics_rest_vs_three[i][j]['Tn_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Fp_pathalogic']), decimal_places)\n",
    "      \n",
    "    ## F-measure\n",
    "    dict_of_metrics_rest_vs_three[i][j]['F_measure_non_pathalogic']   = round((2*dict_of_metrics_rest_vs_three[i][j]['Sensitivity_non_pathalogic']*dict_of_metrics_rest_vs_three[i][j]['Precision_non_pathalogic'])/(dict_of_metrics_rest_vs_three[i][j]['Sensitivity_non_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Precision_non_pathalogic']), decimal_places)\n",
    "    dict_of_metrics_rest_vs_three[i][j]['F_measure_pathalogic']   = round((2*dict_of_metrics_rest_vs_three[i][j]['Sensitivity_pathalogic']*dict_of_metrics_rest_vs_three[i][j]['Precision_pathalogic'])/(dict_of_metrics_rest_vs_three[i][j]['Sensitivity_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Precision_pathalogic']), decimal_places)\n",
    "    \n",
    "    ## Accuracy\n",
    "    dict_of_metrics_rest_vs_three[i][j]['Accuracy'] = round((dict_of_metrics_rest_vs_three[i][j]['Tp_non_pathalogic']+ dict_of_metrics_rest_vs_three[i][j]['Tn_non_pathalogic'])/(dict_of_metrics_rest_vs_three[i][j]['Tp_non_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Fp_non_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Tn_non_pathalogic']+dict_of_metrics_rest_vs_three[i][j]['Fp_non_pathalogic']), decimal_places)\n",
    "\n",
    "\n",
    "for x in dict_of_metrics_rest_vs_three:\n",
    "    print (\"\\033[4m\", x ,\"\\033[0m\", '\\n')\n",
    "    for y in dict_of_metrics_rest_vs_three[x]:\n",
    "      print (y,':',dict_of_metrics_rest_vs_three[x][y])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PmItsw2orh2I"
   },
   "source": [
    "Storing the required results (sensitivity and precision) in a data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.200Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MHgPE7PVrigb"
   },
   "outputs": [],
   "source": [
    "\n",
    "list_of_results = ['Sensitivity_normal','Precision_normal','Sensitivity_non_pathalogic', 'Precision_non_pathalogic']\n",
    "list_of_results_normal = ['Sensitivity_normal','Precision_normal'] \n",
    "list_of_results_non_path = ['Sensitivity_non_pathalogic', 'Precision_non_pathalogic']\n",
    "results = {}\n",
    "\n",
    "for i in activation_funs:\n",
    "  results[i] = {}\n",
    "for i in activation_funs:\n",
    "  for j in list_of_results:\n",
    "    results[i][j] = []\n",
    "\n",
    "for i in activation_funs:\n",
    "  for j in range(1, number_of_models):\n",
    "    for k in list_of_results_normal:\n",
    "      results[i][k].append(dict_of_metrics_one_vs_rest[i][j][k])\n",
    "\n",
    "for i in activation_funs:\n",
    "  for j in range(1, number_of_models):\n",
    "    for k in list_of_results_non_path:\n",
    "      results[i][k].append(dict_of_metrics_rest_vs_three[i][j][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVu6ML6srnSc"
   },
   "source": [
    "Moving the results for different metrics to Pandas DataFrames for easy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.269Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2UCRe7zVrmtj"
   },
   "outputs": [],
   "source": [
    "tanh_results = pd.DataFrame(results['tanh'])\n",
    "relu_results = pd.DataFrame(results['relu'])\n",
    "sigmoid_results = pd.DataFrame(results['sigmoid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJOyl2ndsi3M"
   },
   "source": [
    "Creating labelled and ordered DataFrames for statistical comparison and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.324Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6xvMpeKtsP6g"
   },
   "outputs": [],
   "source": [
    "tanh_vs_relu_sens_normal = pd.concat([tanh_results['Sensitivity_normal'], relu_results['Sensitivity_normal']], axis=1)\n",
    "tanh_vs_relu_sens_normal.columns = ['tanh', 'relu']\n",
    "tanh_vs_relu_precision_normal = pd.concat([tanh_results['Precision_normal'], relu_results['Precision_normal']], axis=1)\n",
    "tanh_vs_relu_precision_normal.columns = ['tanh', 'relu']\n",
    "tanh_vs_relu_sensitivity_non_path = pd.concat([tanh_results['Sensitivity_non_pathalogic'], relu_results['Sensitivity_non_pathalogic']], axis=1)\n",
    "tanh_vs_relu_sensitivity_non_path.columns = ['tanh', 'relu']\n",
    "tanh_vs_relu_precision_non_path = pd.concat([tanh_results['Precision_non_pathalogic'], relu_results['Precision_non_pathalogic']], axis=1)\n",
    "tanh_vs_relu_precision_non_path.columns = ['tanh', 'relu']\n",
    "tanh_vs_sigmoid_sensitivity_normal = pd.concat([tanh_results['Sensitivity_normal'], sigmoid_results['Sensitivity_normal']], axis=1)\n",
    "tanh_vs_sigmoid_sensitivity_normal.columns = ['tanh', 'sigmoid']\n",
    "tanh_vs_sigmoid_precision_normal = pd.concat([tanh_results['Precision_normal'], sigmoid_results['Precision_normal']], axis=1)\n",
    "tanh_vs_sigmoid_precision_normal.columns = ['tanh', 'sigmoid']\n",
    "tanh_vs_sigmoid_sensitivity_non_path = pd.concat([tanh_results['Sensitivity_non_pathalogic'], sigmoid_results['Sensitivity_non_pathalogic']], axis=1)\n",
    "tanh_vs_sigmoid_sensitivity_non_path.columns = ['tanh', 'sigmoid']\n",
    "tanh_vs_sigmoid_precision_non_path = pd.concat([tanh_results['Sensitivity_non_pathalogic'], sigmoid_results['Sensitivity_non_pathalogic']], axis=1)\n",
    "tanh_vs_sigmoid_precision_non_path.columns = ['tanh', 'sigmoid']\n",
    "relu_vs_sigmoid_sensitivity_normal = pd.concat([relu_results['Sensitivity_normal'], sigmoid_results['Sensitivity_normal']], axis=1)\n",
    "relu_vs_sigmoid_sensitivity_normal.columns = ['relu', 'sigmoid']\n",
    "relu_vs_sigmoid_precision_normal = pd.concat([relu_results['Precision_normal'], sigmoid_results['Precision_normal']], axis=1)\n",
    "relu_vs_sigmoid_precision_normal.columns = ['relu', 'sigmoid']\n",
    "relu_vs_sigmoid_sensitivity_non_path = pd.concat([relu_results['Sensitivity_non_pathalogic'], sigmoid_results['Sensitivity_non_pathalogic']], axis=1)\n",
    "relu_vs_sigmoid_sensitivity_non_path.columns = ['relu', 'sigmoid']\n",
    "relu_vs_sigmoid_precision_non_path = pd.concat([relu_results['Precision_normal'], sigmoid_results['Precision_normal']], axis=1)\n",
    "relu_vs_sigmoid_precision_non_path.columns = ['relu', 'sigmoid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3gYY7OLt_qf"
   },
   "source": [
    "# Significance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JU1Of_j4j_8Y"
   },
   "source": [
    "## Sensitivity comparison normal vs abnormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T6GNa_LOsy6y"
   },
   "source": [
    "A box plot comparison of the sensitivity in the normal vs abnormal group for tanh vs relu activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.510Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "PIAghjUJsyiX",
    "outputId": "1a0ad521-da17-4233-a801-99e673c2b39d"
   },
   "outputs": [],
   "source": [
    "tanh_vs_relu_sens_normal.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qk3FszYbtyy3"
   },
   "source": [
    "A box plot comparison of the sensitivity in the normal vs abnormal group for tanh vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.644Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "D8SnX2q_tx8S",
    "outputId": "175dc72d-dc0a-49c4-c28c-4059ce291b5f"
   },
   "outputs": [],
   "source": [
    "tanh_vs_sigmoid_sensitivity_normal.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kd2vGjIWesaL"
   },
   "source": [
    "A box plot comparison of the sensitivity in the normal vs abnormal group for relu vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.702Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "n59O-Ht2efqk",
    "outputId": "30e4f7f3-72ba-428e-e942-9c5181d8082d"
   },
   "outputs": [],
   "source": [
    "relu_vs_sigmoid_sensitivity_normal.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SI_V8SEuGpf"
   },
   "source": [
    "Here the difference in sensitivity for the normal vs abnormal group is compared to the 5% significance level for the tanh vs relu, tanh vs sigmoid and relu vs sigmoid experiments. The Wilcoxon signed-rank test is used as it is a non parametric test suitable for data without a normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.758Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "aE8i07fTuEd3",
    "outputId": "521159c2-0d79-41f9-f3bc-2206275a0697"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "s, p = stats.wilcoxon(tanh_results['Sensitivity_normal'], relu_results['Sensitivity_normal'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.761Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dgBU1qZ3HOfi",
    "outputId": "804e7012-ed6c-473f-fa8c-30802f112315"
   },
   "outputs": [],
   "source": [
    "s, p = stats.wilcoxon(tanh_results['Sensitivity_normal'], sigmoid_results['Sensitivity_normal'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:41.763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kLkgV9bvH1bw",
    "outputId": "c32596eb-dd82-4f01-e797-4682c701b6c8"
   },
   "outputs": [],
   "source": [
    "s, p = stats.wilcoxon(relu_results['Sensitivity_normal'], sigmoid_results['Sensitivity_normal'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMDdUidAubBf"
   },
   "source": [
    "From this we can conclude that in the tanh and relu experiment for the normal vs abnormal classification problem the **sensitivity is not significantly affected** by the change of activation function in the hidden layers of the neural networks. This is tested at the 5% significance level. Therefore we accept the null hypothesis that changing the activation function from tanh to relu in the hidden layers does not significantly affect the sensitivity of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmFj0XaFf0Hr"
   },
   "source": [
    "We can also conclude that in the tanh and sigmoid experiment for the normal vs abnormal classification problem the **sensitivity is significantly affected** by the change of activation function in the hidden layers of the neural networks. This is also tested at the 5% significance level. We can therefore reject the null hypothesis in favour of the alternative hypothesis indicating that changing the activation function from tanh to sigmoid in the hidden layers of the classifier does significantly affect the sensitivity of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrpU5XqjgxF8"
   },
   "source": [
    "We can further conclude that in the relu and sigmoid experiment for the normal vs abnormal classification problem the **sensitivity is significantly affected** by the change of activation function in the hidden layers of the neural networks. This is also tested at the 5% significance level. We can therefore reject the null hypothesis in favour of the alternative hypothesis indicating that changing the activation function from relu to sigmoid in the hidden layers of the classifier does significantly affect the sensitivity of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rT4Gr-Gwktv2"
   },
   "source": [
    "## Precision comparison normal vs abnormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9c8F_kwktv7"
   },
   "source": [
    "A box plot comparison of the precision in the normal vs abnormal group for tanh vs relu activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.123Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "pOrNGRaVktv8",
    "outputId": "eb329b0f-b2e1-4cee-b4f7-17b74366f7d5"
   },
   "outputs": [],
   "source": [
    "tanh_vs_relu_precision_normal.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdY_LjbMktwB"
   },
   "source": [
    "A box plot comparison of the precision in the normal vs abnormal group for tanh vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.173Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "szFLg6R4ktwC",
    "outputId": "55607f0a-ad33-45ec-bf99-5db240c20caa"
   },
   "outputs": [],
   "source": [
    "tanh_vs_sigmoid_precision_normal.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8D8Y0YHvktwE"
   },
   "source": [
    "A box plot comparison of the precision in the normal vs abnormal group for relu vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.228Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "Ijy0Au3LktwF",
    "outputId": "9b46d76b-c51d-4865-cd43-8c55f4fecc84"
   },
   "outputs": [],
   "source": [
    "relu_vs_sigmoid_precision_normal.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6QavE3RktwH"
   },
   "source": [
    "Here the difference in precision for the normal vs abnormal group is compared to the 5% significance level for the tanh vs relu, tanh vs sigmoid and relu vs sigmoid experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.281Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6RG6WqihktwI",
    "outputId": "50160e8d-5cb9-4739-917a-d1ab31ca3450"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "s, p = stats.wilcoxon(tanh_results['Precision_normal'], relu_results['Precision_normal'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.283Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ftqAs63AktwJ",
    "outputId": "d8aa5f1f-615f-4835-f8df-38d1b7956870"
   },
   "outputs": [],
   "source": [
    "s, p = stats.wilcoxon(tanh_results['Precision_normal'], sigmoid_results['Precision_normal'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.286Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "54OZYNu1ktwL",
    "outputId": "efe28ced-17ff-422a-9c39-9cccb16767c5"
   },
   "outputs": [],
   "source": [
    "s, p = stats.wilcoxon(relu_results['Precision_normal'], sigmoid_results['Precision_normal'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bjf2ru_aktwO"
   },
   "source": [
    "From this we can conclude that in the tanh and relu experiment for the normal vs abnormal classification problem the **precision is not significantly affected** by the change of activation function in the hidden layers of the neural networks. This is tested at the 5% significance level. Therefore we accept the null hypothesis that changing the activation function from tanh to relu in the hidden layers does not significantly affect the precision of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRg8DPFLktwO"
   },
   "source": [
    "We can also conclude that in the tanh and sigmoid experiment for the normal vs abnormal classification problem the **precision is not significantly affected** by the change of activation function in the hidden layers of the neural networks. This is also tested at the 5% significance level. We can therefore accept the null hypothesis indicating that changing the activation function from tanh to sigmoid in the hidden layers of the classifier does not significantly affect the precision of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vu2qBKBOktwP"
   },
   "source": [
    "We can further conclude that in the relu and sigmoid experiment for the normal vs abnormal classification problem the **precision is significantly affected** by the change of activation function in the hidden layers of the neural networks. This is also tested at the 5% significance level. We can therefore reject the null hypothesis in favour of the alternative hypothesis indicating that changing the activation function from relu to sigmoid in the hidden layers of the classifier does significantly affect the precision of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPGxUayfmejq"
   },
   "source": [
    "# Sensitivity comparison for non pathologic vs pathologic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GeLdCunmJLv"
   },
   "source": [
    "A box plot comparison of the sensitivity in the non pathologic vs pathologic group for tanh vs relu activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.620Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "BPQHbdJzmJLw",
    "outputId": "24d40f5e-44e1-43bc-beec-a5a3ad2937a2"
   },
   "outputs": [],
   "source": [
    "tanh_vs_relu_sensitivity_non_path.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bI95n-GvmJL0"
   },
   "source": [
    "A box plot comparison of the precision in the normal vs abnormal group for tanh vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.680Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "XS06B8iXmJL0",
    "outputId": "f03e37ef-cdc7-493f-ce08-d4bce8773f26"
   },
   "outputs": [],
   "source": [
    "tanh_vs_sigmoid_sensitivity_non_path.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSdM-5eimJL2"
   },
   "source": [
    "A box plot comparison of the precision in the normal vs abnormal group for relu vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.766Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "l00tuh3dmJL3",
    "outputId": "0524dfdc-26d1-40ea-834b-4c2b703f5326"
   },
   "outputs": [],
   "source": [
    "relu_vs_sigmoid_sensitivity_non_path.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AhAVT_ymJL6"
   },
   "source": [
    "Here the difference in precision for the normal vs abnormal group is compared to the 5% significance level for tanh vs relu, tanh vs sigmoid and relu vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.826Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "SaS8Q5upmJL6",
    "outputId": "3c0e42b4-36f9-4c42-8e71-1f72993da70e"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "s, p = stats.wilcoxon(tanh_results['Sensitivity_non_pathalogic'], relu_results['Sensitivity_non_pathalogic'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.829Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mo0zlH5vmJL8",
    "outputId": "f1308377-d5e8-4316-b674-35f1d3cae350"
   },
   "outputs": [],
   "source": [
    "s, p = stats.wilcoxon(tanh_results['Sensitivity_non_pathalogic'], sigmoid_results['Sensitivity_non_pathalogic'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:42.831Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "t7FOSElVmJL9",
    "outputId": "ab635cab-2844-4dc5-f2c3-c5e864b30ea7"
   },
   "outputs": [],
   "source": [
    "s, p = stats.wilcoxon(relu_results['Sensitivity_non_pathalogic'], sigmoid_results['Sensitivity_non_pathalogic'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo66m2SemJL_"
   },
   "source": [
    "From this we can conclude that in the tanh and relu experiment for the non pathologic vs pathologic classification problem the **sensitivity is not significantly affected** by the change of activation function in the hidden layers of the neural networks. This is tested at the 5% significance level. Therefore we accept the null hypothesis that changing the activation function from tanh to relu in the hidden layers does not significantly affect the sensitivity of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2ty5IN_mJL_"
   },
   "source": [
    "We can also conclude that in the tanh and sigmoid experiment for the non pathologic vs pathologic classification problem the **sensitivity is not significantly affected** by the change of activation function in the hidden layers of the neural networks. This is also tested at the 5% significance level. We can therefore accept the null hypothesis indicating that changing the activation function from tanh to sigmoid in the hidden layers of the classifier does not significantly affect the sensitivity of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CX8npXTVmJMA"
   },
   "source": [
    "We can further conclude that in the relu and sigmoid experiment for the non pathologic vs pathologic classification problem the **sensitivity is significantly affected** by the change of activation function in the hidden layers of the neural networks. This is also tested at the 5% significance level. We can therefore reject the null hypothesis in favour of the alternative hypothesis indicating that changing the activation function from relu to sigmoid in the hidden layers of the classifier does significantly affect the sensitivity of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ys7dKSGJm146"
   },
   "source": [
    "# Precision comparison non pathologic vs pathologic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hd3IdeARm149"
   },
   "source": [
    "A box plot comparison of the precision in the non pathologic vs pathologic group for tanh vs relu activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:43.118Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "EwBX_gEnm149",
    "outputId": "48b3c55c-e2f3-4ccb-cecd-128b0419523f"
   },
   "outputs": [],
   "source": [
    "tanh_vs_relu_precision_non_path.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yBJ9bRem15A"
   },
   "source": [
    "A box plot comparison of the precision in the non pathologic vs pathologic group for tanh vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:43.176Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "Iwk8pTJ-m15A",
    "outputId": "0a9d61bd-ba95-424f-8971-998619e19adb"
   },
   "outputs": [],
   "source": [
    "tanh_vs_sigmoid_precision_non_path.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmD0YrIqm15C"
   },
   "source": [
    "A box plot comparison of the precision in the non pathologic vs pathologic group for relu vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:43.238Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "XVTRigdJm15C",
    "outputId": "997f907e-9760-4608-e009-5258ffae1fa1"
   },
   "outputs": [],
   "source": [
    "relu_vs_sigmoid_precision_non_path.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0oOinLrm15E"
   },
   "source": [
    "Here the difference in precision for the non pathologic vs pathologic group is compared to the 5% significance level for tanh vs relu, tanh vs sigmoid and relu vs sigmoid activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:43.298Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "ZPJ7Xq1zm15E",
    "outputId": "f10025fc-0962-4364-8aca-b9d63f06ad34"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "s, p = stats.wilcoxon(tanh_results['Precision_non_pathalogic'], relu_results['Precision_non_pathalogic'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:43.301Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6ehzghZVm15G",
    "outputId": "61367c3d-1716-4f36-c751-151140ca8a3c"
   },
   "outputs": [],
   "source": [
    "s, p = stats.wilcoxon(tanh_results['Precision_non_pathalogic'], sigmoid_results['Precision_non_pathalogic'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-05T23:13:43.303Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-oxdekzFm15H",
    "outputId": "b93b8ace-abc8-4cda-e743-dcbf0bdff021"
   },
   "outputs": [],
   "source": [
    "s, p = stats.wilcoxon(relu_results['Precision_non_pathalogic'], sigmoid_results['Precision_non_pathalogic'])\n",
    "\n",
    "if p < 0.05:\n",
    "  print('null hypothesis rejected, significant difference between the data-sets')\n",
    "else:\n",
    "  print('null hypothesis accepted, no significant difference between the data-sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hGYH9jim15J"
   },
   "source": [
    "From this we can conclude that in the tanh and relu experiment for the non pathologic vs pathologic classification problem the **precision is not significantly affected** by the change of activation function in the hidden layers of the neural networks. This is tested at the 5% significance level. Therefore we accept the null hypothesis that changing the activation function from tanh to relu in the hidden layers does not significantly affect the precision of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlhA_TiBm15K"
   },
   "source": [
    "We can also conclude that in the tanh and sigmoid experiment for the non pathologic vs pathologic classification problem the **precision is not significantly affected** by the change of activation function in the hidden layers of the neural networks. This is also tested at the 5% significance level. We can therefore accept the null hypothesis  indicating that changing the activation function from tanh to sigmoid in the hidden layers of the classifier does not significantly affect the precision of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97h3K76lm15K"
   },
   "source": [
    "We can further conclude that in the relu and sigmoid experiment for the non pathologic vs pathologic classification problem the **precision is not significantly affected** by the change of activation function in the hidden layers of the neural networks. This is also tested at the 5% significance level. We can therefore accept the null hypothesis indicating that changing the activation function from relu to sigmoid in the hidden layers of the classifier does significantly affect the precision of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZjpdJN3etg2g"
   },
   "source": [
    "# Normal vs abnormal conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ev2oUfYotmVW"
   },
   "source": [
    "Tanh and relu consistently perform better than sigmoid on sensitivity but it is not possible to determine which of tanh or relu has the highest sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_nwQ_-Gft6--"
   },
   "source": [
    "For precision, tanh vs relu and tanh vs sigmoid give no significant difference in precision but we can conclusively say that sigmoid gives a statistically significant higher precision on average than relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2Wi8gjRubpe"
   },
   "source": [
    "All tested to the 5% significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4XnI5v9uho2"
   },
   "source": [
    "A higher sensitivity indicates a lower amount of missed abnormalities (missed false negatives). Due to this, if the expert requires a classifier not miss false negatives the tanh and relu activation functions are recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04-HFSrnvVwG"
   },
   "source": [
    "A high precision indicates avoiding false positive readings. If the expert requires a very precise classifier then we would have to perform more tests to conclusively decide on which activation function to recommend. This is because tanh and relu show no significant difference, tanh and sigmoid show no significant difference but sigmoid significantly outperforms relu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x16G-Y3-wP6I"
   },
   "source": [
    "# Non pathologic vs pathologic conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tp4AwXWqwTlG"
   },
   "source": [
    "Tanh vs relu and tanh vs sigmoid show no significant difference in sensitivity but sigmoid significantly outperforms relu in sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzkR6WEIwnLW"
   },
   "source": [
    "For precision, all experiments were found to be inconclusive meaning that there is no significant difference in precision between any of the activation functions used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B62k9IMKw5OG"
   },
   "source": [
    "If the expert requires high sensitivity then more tests are required to determine which activation function should be recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-aUGDl2UyLM2"
   },
   "source": [
    "If the expert requires high precision then it does not matter which activation function is recommended since they all perform at the same level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04PVFTHMzgq9"
   },
   "source": [
    "# Conclusion\n",
    "We rely on our expert to advse us if it is appropriate to group babies as normal/abnormal in which case we can recommend a classifier or pathologic/non pathologic in which case we need to conduct more experiments.\n",
    "Future work could include running with more models, using a different sampling technique like SMOTE or changing the way we train the model e.g. different batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B83jU2uMvX-_"
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9CDW4KzcsuQ"
   },
   "source": [
    "Ayres-de Campos, D., Bernardes, J., Garrido, A., Marques-de-S, J. and Pereira-Leite, L., 2000. *SisPorto 2.0: a program for automated analysis of cardiotocograms*. The Journal Of Maternal-Fetal Medicine, 9 (5), 311-318.\n",
    "FIGO *Intrapartum foetal Monitoring Guidelines*.[Online] https://www.figo.org/news/available-view-figo-intrapartum-fetal-monitoring-guidelines-0015088. [Accessed 22 Oct. 2019].\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NJSBC8JdvVeP"
   },
   "source": [
    " Haibo, H., Yang, B., Garcia, E. A. and Shutao, L., 2008. *ADASYN: Adaptive synthetic sampling approach for imbalanced learning* (pp. 1322-1328): IEEE.\n",
    " Kingma D.P. and Ba, J. 2014. *Adam: A Method for Stochastic Optimization.*[Online] https://arxiv.org/abs/1412.6980. [Accessed 3 Dec. 2019].\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2u2k1HkMhHC0"
   },
   "source": [
    " Marques de S, J.P., Bernardes, J, Ayres de Campos, D., 2008. *Cardiotocography Data Set*\n",
    "\n",
    " *[Online] https://archive.ics.uci.edu/ml/datasets/cardiotocography. [Accessed 3 Oct. 2019].\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JU1Of_j4j_8Y",
    "rT4Gr-Gwktv2",
    "rPGxUayfmejq"
   ],
   "name": "Cardiotocography Data Set visualisation_12122019.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
